---
title: "Project"
author: "Avjot Buttar"
date: "2024-04-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
cat("\014")  # Clear Console
rm(list = ls(all.names = TRUE))# clear all
gc()
```

```{r get dataset}
air <- read.csv("listings-complete.csv")
```

```{r air_clean}
library(tidyverse)
library(dplyr)

colnames(air)
# Convert character columns to factors in the dataset
air <- air %>% mutate_if(is.character, as.factor) 

# Extract numbers from "bathrooms_text" and convert to numeric
air$bathrooms <- as.numeric(gsub("[^0-9.]+", "", air$bathrooms_text))

# Define the selected variables for analysis
selected_variables <- c(
  "host_is_superhost", "host_response_time", "host_response_rate", 
  "host_acceptance_rate", "accommodates", 
  "bathrooms", "bedrooms", "price", "neighbourhood_cleansed", 
  "host_listings_count", "minimum_nights", "maximum_nights", 
  "instant_bookable", "host_identity_verified", "availability_30", 
  "availability_60", "availability_90","review_scores_rating","reviews_per_month", "has_availability","availability_365","number_of_reviews"
)

# Create a new dataframe with only the selected variables
air_new <- air[selected_variables]

# Remove rows with NA values from air_new
air_clean <- na.omit(air_new)


# Check the structure of air_clean
str(air_clean)

# Convert "price" column to numeric
air_clean$price <- as.numeric(gsub("[$,]", "", air_clean$price))

# Convert "host_acceptance_rate" and "host_response_rate" columns to numeric
air_clean$host_acceptance_rate <- as.numeric(gsub("%", "", air_clean$host_acceptance_rate)) / 100
air_clean$host_response_rate <- as.numeric(gsub("%", "", air_clean$host_response_rate)) / 100

# Check the structure of air_clean again
str(air_clean)

# Summarize the cleaned dataset
summary(air_clean)

# Calculate the count of bathrooms
bathrooms_count <- table(air_clean$bathrooms)

```

```{r simple histograms and current statistics, fig.height=6, fig.width=10}
library(ggplot2)

p = ggplot(air_clean, aes(y = air_clean$price, x = air_clean$accommodates)) + geom_point() + facet_wrap(~air_clean$bedrooms)
print(p + labs(title = "Price compared to accommodation size split by bedrooms (Model 1)", y = "Price", x = "Accommodates"))

p = ggplot(air_clean, aes(y = air_clean$price, x = air_clean$accommodates)) + geom_point() + facet_wrap(~air_clean$bathrooms)
print(p + labs(title = "Price compared to accommodation size split by bathrooms (Model 1)", y = "Price", x = "Accommodates"))

p = ggplot(air_clean, aes(y = air_clean$price, x = air_clean$bathrooms)) + geom_point()
print(p + labs(title = "Price compared to bathrooms (Model 1)", y = "Price", x = "Bathrooms"))

p = ggplot(air_clean, aes(y = air_clean$price, x = air_clean$number_of_reviews)) + geom_point()
print(p + labs(title = "Price compared to the number of reviews (Model 1)", y = "Price", x = "Number of reviews"))
```

```{r correlations}
# Calculate correlation matrix
correlation_matrix <- model.matrix(~0 + ., air_clean) %>%
  cor(use = "pairwise.complete.obs")

# Identify correlations with the "y" variable (price)
review_correlations <- correlation_matrix["price",]

# Sort correlations in descending order to identify predictors
sorted_correlations <- sort(review_correlations, decreasing = TRUE)

# Convert sorted correlations to a data frame
correlation_df <- data.frame(Predictor_Variable = names(sorted_correlations), Correlation_with_y = sorted_correlations)

options(scipen = 999)
# Print the sorted correlations table
print(correlation_df)

```

```{r correlation graph, fig.height=10, fig.width=10}
#install.packages("plotly")
require(plotly)
m <- list(
  l =  10,
  r = 10,
  b = 10,
  t = 10,
  pad = 1
)
heatmap <- plot_ly(x=colnames(correlation_matrix), y=rownames(correlation_matrix), z = correlation_matrix, type="heatmap",
    colors=colorRamp(c("darkblue","white","darkred"))) %>%
    layout(margin = m)

#save graph as an html
#htmlwidgets::saveWidget(as_widget(heatmap), "heatmap.html")

heatmap
```

This is the kitchen sink model of OLS. This includes all of variables without any data transformations.

```{r air_clean step_model}
# Load the required library for linear regression
library(stats)


# Define the linear regression model using selected variables
model <- lm(price ~ host_is_superhost + host_response_time + host_response_rate + host_acceptance_rate +
               accommodates + bathrooms + bedrooms + neighbourhood_cleansed + host_listings_count + 
               minimum_nights + maximum_nights + instant_bookable + host_identity_verified + 
               availability_30 + availability_60 + availability_90 + review_scores_rating + reviews_per_month + has_availability, 
            data = air_clean)

# Print the summary of the model to check coefficients and other statistics
summary(model)

# Remove rows with missing values
air_clean <- na.omit(air_clean)


# Perform stepwise selection
step_model <- step(model)

# Summary of the model with stepwise selection
summary(step_model)

```

```{r simple histograms and current statistics air_clean, fig.height=6, fig.width=10}
p = ggplot(air_clean, aes(y = air_clean$price, x = air_clean$accommodates)) + geom_point() + facet_wrap(~air_clean$bedrooms)
print(p + labs(title = "Price compared to accommodation size split by bedrooms (Model 2)", y = "Price", x = "Accommodates"))

p = ggplot(air_clean, aes(y = air_clean$price, x = air_clean$accommodates)) + geom_point() + facet_wrap(~air_clean$bathrooms) + geom_boxplot(aes(group = air_clean$accommodates))
print(p + labs(title = "Price compared to accommodation size split by bathrooms (Model 2)", y = "Price", x = "Accommodates")) 

p = ggplot(air_clean, aes(y = air_clean$price, x = air_clean$bathrooms)) + geom_boxplot(aes(group = air_clean$bathrooms))
print(p + labs(title = "Price compared to bathrooms (Model 2)", y = "Price", x = "Bathrooms"))

p = ggplot(air_clean, aes(y = air_clean$price, x = air_clean$number_of_reviews)) + geom_point()
print(p + labs(title = "Price compared to the number of reviews (Model 2)", y = "Price", x = "Number of reviews"))
```

In this chunk of code I got rid of non-signficant neighbourhoods.

```{r air_clean_sig step_model2}
# Create a vector of significant neighbourhoods
significant_neighborhoods <- c("Downtown", "Downtown Eastside","Kitsilano", "Hastings-Sunrise","Kerrisdale", "Killarney","Marpole", "Mount Pleasant", "Oakridge", "Renfrew-Collingwood","Sunset", "Victoria-Fraserview", "West End")

# Filter the dataset to include only significant neighbourhoods
air_clean_sig <- air_clean %>%
  filter(neighbourhood_cleansed %in% significant_neighborhoods)

# Fit a linear regression model with significant neighbourhoods
lm_model_significant_neighborhoods <- lm(price ~ host_is_superhost + host_response_time + host_response_rate + host_acceptance_rate +
               accommodates + bathrooms + bedrooms + neighbourhood_cleansed + host_listings_count + 
               minimum_nights + maximum_nights + instant_bookable + host_identity_verified + 
               availability_30 + availability_60 + availability_90 + review_scores_rating + reviews_per_month + has_availability, 
                                       data = air_clean_sig)



# Perform stepwise selection on the model
step_model2 <- step(lm_model_significant_neighborhoods)

# Summary of the model with stepwise selection
summary(step_model2)


```

```{r simple histograms and current statistics air_clean_sig, fig.height=6, fig.width=10}
p = ggplot(air_clean_sig, aes(y = air_clean_sig$price, x = air_clean_sig$accommodates)) + geom_point() + facet_wrap(~air_clean_sig$bedrooms)
print(p + labs(title = "Price compared to accommodation size split by bedrooms", y = "Price", x = "Accommodates"))

p = ggplot(air_clean_sig, aes(y = air_clean_sig$price, x = air_clean_sig$accommodates)) + geom_point() + facet_wrap(~air_clean_sig$bathrooms) + geom_boxplot(aes(group = air_clean_sig$accommodates))
print(p + labs(title = "Price compared to accommodation size split by bathrooms", y = "Price", x = "Accommodates")) 

p = ggplot(air_clean_sig, aes(y = air_clean_sig$price, x = air_clean_sig$bathrooms)) + geom_boxplot(aes(group = air_clean_sig$bathrooms))
print(p + labs(title = "Price compared to bathrooms", y = "Price", x = "Bathrooms"))

p = ggplot(air_clean_sig, aes(y = air_clean_sig$price, x = air_clean_sig$number_of_reviews)) + geom_point()
print(p + labs(title = "Price compared to the number of reviews", y = "Price", x = "Number of reviews"))
```

In this code I transformed the data so that it removed extreme outliers form the data

```{r air_clean_filtered}
# Function to detect outliers using IQR and remove them
remove_outliers <- function(data, variable) {
  q1 <- quantile(data[[variable]], 0.25)
  q3 <- quantile(data[[variable]], 0.75)
  iqr <- q3 - q1
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 4.5 * iqr
  
  # Remove outliers from the data frame
  filtered_data <- data[!(data[[variable]] < lower_bound | data[[variable]] > upper_bound), ]
  return(filtered_data)
}

# Remove outliers from the 'price' variable in air_clean
air_clean_filtered <- remove_outliers(air_clean, 'price')

```

```{r simple histograms and current statistics air_clean_filtered, fig.height=6, fig.width=10}
p = ggplot(air_clean_filtered, aes(y = air_clean_filtered$price, x = air_clean_filtered$accommodates)) + geom_point() + facet_wrap(~air_clean_filtered$bedrooms)
print(p + labs(title = "Price compared to accommodation size split by bedrooms (Model 3)", y = "Price", x = "Accommodates"))

p = ggplot(air_clean_filtered, aes(y = air_clean_filtered$price, x = air_clean_filtered$accommodates)) + geom_point() + facet_wrap(~air_clean_filtered$bathrooms) 
#+ geom_boxplot(aes(group = air_clean_filtered$accommodates))
print(p + labs(title = "Price compared to accommodation size split by bathrooms (Model 3)", y = "Price", x = "Accommodates")) 

p = ggplot(air_clean_filtered, aes(y = air_clean_filtered$price, x = air_clean_filtered$bathrooms)) + geom_boxplot(aes(group = air_clean_filtered$bathrooms)) + geom_smooth()
print(p + labs(title = "Price compared to bathrooms (Model 3)", y = "Price", x = "Bathrooms"))

p = ggplot(air_clean_filtered, aes(y = air_clean_filtered$price, x = air_clean_filtered$number_of_reviews)) + geom_point()
print(p + labs(title = "Price compared to the number of reviews (Model 3)", y = "Price", x = "Number of reviews"))
```

This model has the data without outliers and with all neighbourhoods.

```{r step_model3}
# Fit a linear regression model with filtered data
updated_model <- lm(price ~ host_is_superhost + host_response_time + 
                      host_response_rate + host_acceptance_rate + 
                      accommodates + bathrooms + bedrooms + 
                      neighbourhood_cleansed + host_listings_count + 
                      minimum_nights + maximum_nights + instant_bookable + 
                      host_identity_verified + availability_30 + 
                      availability_60 + availability_90 + 
                      review_scores_rating + reviews_per_month,
                    data = air_clean_filtered)

# Summary of the updated model
summary(updated_model)

# Perform stepwise selection on the updated model
step_model3 <- step(updated_model)

# Summary of the model with stepwise selection
summary(step_model3)

```

This model has the outliers removed and only significant neighbourhoods

```{r air_clean_sig2 step_model4}
# Filter the dataset to include only significant neighbourhoods with filtered data
air_clean_sig2 <- air_clean_filtered %>%
  filter(neighbourhood_cleansed %in% significant_neighborhoods)

# Fit a linear regression model with significant neighbourhoods and filtered data
lm_model_significant_neighborhoods2 <- lm(price ~ host_is_superhost + host_response_time + 
                      host_response_rate + host_acceptance_rate + 
                      accommodates + bathrooms + bedrooms + 
                      neighbourhood_cleansed + host_listings_count + 
                      minimum_nights + maximum_nights + instant_bookable + 
                      host_identity_verified + availability_30 + 
                      availability_60 + availability_90 + 
                      review_scores_rating + reviews_per_month, 
                                       data = air_clean_sig2)

# Get the summary of the model with significant neighbourhoods and filtered data
summary(lm_model_significant_neighborhoods2)

# Perform stepwise selection on the model
step_model4 <- step(lm_model_significant_neighborhoods2)

# Summary of the model with stepwise selection
summary(step_model4)



```

```{r simple histograms and current statistics air_clean_sig2, fig.height=6, fig.width=10}
p = ggplot(air_clean_sig2, aes(y = air_clean_sig2$price, x = air_clean_sig2$accommodates)) + geom_point() + facet_wrap(~air_clean_sig2$bedrooms)
print(p + labs(title = "Price compared to accommodation size split by bedrooms (Model 4)", y = "Price", x = "Accommodates"))

p = ggplot(air_clean_sig2, aes(y = air_clean_sig2$price, x = air_clean_sig2$accommodates)) + geom_point() + facet_wrap(~air_clean_sig2$bathrooms) + geom_boxplot(aes(group = air_clean_sig2$accommodates))
print(p + labs(title = "Price compared to accommodation size split by bathrooms (Model 4)", y = "Price", x = "Accommodates")) 

p = ggplot(air_clean_sig2, aes(y = air_clean_sig2$price, x = air_clean_sig2$bathrooms)) + geom_boxplot(aes(group = air_clean_sig2$bathrooms)) + geom_smooth()
print(p + labs(title = "Price compared to bathrooms (Model 4)", y = "Price", x = "Bathrooms"))

p = ggplot(air_clean_sig2, aes(y = air_clean_sig2$price, x = air_clean_sig2$number_of_reviews)) + geom_point()
print(p + labs(title = "Price compared to the number of reviews (Model 4)", y = "Price", x = "Number of reviews"))
```

Comparing of Models

```{r}
# Load the stargazer package
library(stargazer)

# Create a list of your models
models_list <- list(step_model, step_model2, step_model3)

# Display the comparison using stargazer with smaller output
stargazer(models_list, type = "text", title = "Model Comparison",
          column.labels = c("Model 1", "Model 2", "Model 3"),
          header = FALSE, single.row = TRUE, font.size = "small")



options(scipen = 999)


# Diagnostic plot: Residuals vs Fitted
residuals_vs_fitted <- ggplot(air_clean_filtered, aes(x = fitted(step_model3), y = residuals(step_model3))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  xlab("Fitted Values") +
  ylab("Residuals") +
  ggtitle("Residuals vs Fitted Model 3")

# Show the plot
print(residuals_vs_fitted)

# Get the residuals from the model
residuals <- residuals(step_model3)

# Create a histogram of the residuals
hist(residuals, breaks = 30, main = "Histogram of Residuals OLS Model 3", xlab = "Residuals")

# Diagnostic plot: Residuals vs Fitted
residuals_vs_fitted2 <- ggplot(air_clean, aes(x = fitted(step_model), y = residuals(step_model))) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  xlab("Fitted Values") +
  ylab("Residuals") +
  ggtitle("Residuals vs Fitted Model 1")

# Show the plot
print(residuals_vs_fitted2)


# Get the residuals from the model
residuals2 <- residuals(step_model)
# Create a histogram of the residuals
hist(residuals2, breaks = 30, main = "Histogram of Residuals OLS Model 1", xlab = "Residuals")


```

```{r}
library(rpart)
library(caret)
library(rpart.plot)
library(e1071)

# Calculate the median price
median_price <- median(air_clean_filtered$price)

# Create a binary variable based on median price
air_clean_filtered$price_binary <- ifelse(air_clean_filtered$price > median_price, "Above Median", "Below Median")

# Convert character columns to factors in the dataset
air_clean_filtered <- air_clean_filtered %>% mutate_if(is.character, as.factor)

# Set the seed for reproducibility
set.seed(123)

# Randomize the order of the data
air_clean_filtered <- air_clean_filtered[sample(nrow(air_clean_filtered)), ]

# Split the data into training (70%) and testing (30%) sets
train_index <- createDataPartition(air_clean_filtered$price, p = 0.7, list = FALSE)
train_data <- air_clean_filtered[train_index, ]
test_data <- air_clean_filtered[-train_index, ]

# Fit the decision tree model using the training data
tree_model <- rpart(price_binary ~  host_is_superhost + host_response_time + 
                      host_response_rate + host_acceptance_rate + 
                      accommodates + bathrooms + bedrooms + 
                      neighbourhood_cleansed + host_listings_count + 
                      minimum_nights + maximum_nights + instant_bookable + 
                      host_identity_verified + availability_30 + 
                      availability_60 + availability_90 + 
                      review_scores_rating + reviews_per_month , data = train_data)

# Visualize the decision tree
rpart.plot(tree_model)

# Convert character columns to factors in the dataset
air_clean_filtered <- air_clean_filtered %>% mutate_if(is.character, as.factor)



# Get the variable importance from the model
variable_importance <- tree_model$variable.importance

# Calculate the total importance sum
total_importance <- sum(variable_importance)

# Calculate the percentage importance for each variable
percentage_importance <- (variable_importance / total_importance) * 100

# Sort variable importance in descending order
sorted_percentage <- sort(percentage_importance, decreasing = TRUE)

# Print sorted percentage importance
print(sorted_percentage)
```

```{r}
# Create a subset of the dataset with the selected input variables and the target variable of binary price

data_subset <- air_clean_filtered %>%
  select(c(selected_variables, "price_binary"))

# Set up the training control for 10-fold cross-validation
train_control <- trainControl(method = "cv", number = 10)

# Define the grid of k values to test
k_values <- data.frame(k = c(1, 3, 5, 7, 9, 11,13))  # Adjust as needed

# Fit the KNN model with different k values and perform 10-fold cross-validation
knn_model <- train(price_binary ~ ., data = data_subset, method = "knn", trControl = train_control, tuneGrid = k_values)

# Plot model accuracy vs. Number of Neighbors (K)
plot(knn_model, main = "Model Accuracy vs. Number of Neighbors (K)", xlab = "Number of Neighbors (K)", ylab = "Accuracy")


# Train KNN model using caret and evaluate performance
knn_model <- train( price_binary~ ., data = train_data, method = "knn", trControl = train_control)
knn_predictions <- predict(knn_model, test_data)

 

# Compute the confusion matrix
knn_metrics <- confusionMatrix(knn_predictions, test_data$price_binary)
print(knn_metrics)


# Calculate precision and recall for the KNN model
knn_precision <- knn_metrics$byClass["Precision"]
knn_recall <- knn_metrics$byClass["Recall"]

print("KNN Metrics:")
print(paste("Accuracy:", knn_metrics$overall["Accuracy"]))
print(paste("Precision:", knn_precision))
print(paste("Recall:", knn_recall))
```

```{r}
# Create a new data frame for the specific Airbnb listing
new_listing <- data.frame(
  host_is_superhost = "f",  # Assuming the host is not a superhost
  host_response_time = "within a day",  # Assuming response time within a day
  host_response_rate = 0.95,  # Assuming a 95% response rate
  host_acceptance_rate = 0.97,  # Assuming an 85% acceptance rate
  accommodates = 4,  # Number of people accommodated
  bathrooms = 1,  # Number of bathrooms
  bedrooms = 2,  # Number of bedrooms
  neighbourhood_cleansed = "Kitsilano",  # Neighborhood name
  host_listings_count = 3,  # Number of host listings
  minimum_nights = 2,  # Minimum nights required for booking
  maximum_nights = 30,  # Maximum nights allowed for booking
  instant_bookable = "f",  # Assuming instant booking is not available
  host_identity_verified = "t",  # Assuming host identity is verified
  availability_30 = 25,  # Availability in the next 30 days
  availability_60 = 50,  # Availability in the next 60 days
  availability_90 = 70,  # Availability in the next 90 days
  review_scores_rating = 4.5,  # Review scores rating
  reviews_per_month = 2,  # Reviews per month
  has_availability = "t",  # Assuming availability is true
  availability_365 = 300,  # Availability in the next 365 days
  number_of_reviews = 50   # Total number of reviews
  
)

# Predict prices using all models and print them
print("Predicted Price from Model 1:")
print(predict(step_model, newdata = new_listing))

print("Predicted Price from Model 2:")
print(predict(step_model2, newdata = new_listing))

print("Predicted Price from Model 3:")
print(predict(step_model3, newdata = new_listing))




```

Distribution of price in different datasets

```{r}
# Load the ggplot2 library
library(ggplot2)

# Create a histogram of the price distribution
ggplot(air_clean, aes(x = price)) +
  geom_histogram(binwidth = 25, color = "black", fill = "skyblue", alpha = 0.8) +
  labs(title = "Distribution of Price Model 1", x = "Price", y = "Frequency") +
  theme_minimal()


# Create a histogram of the price distribution
ggplot(air_clean_sig, aes(x = price)) +
  geom_histogram(binwidth = 25, color = "black", fill = "skyblue", alpha = 0.8) +
  labs(title = "Distribution of Price Model 2", x = "Price", y = "Frequency") +
  theme_minimal()

# Create a histogram of the price distribution
ggplot(air_clean_filtered, aes(x = price)) +
  geom_histogram(binwidth = 25, color = "black", fill = "skyblue", alpha = 0.8) +
  labs(title = "Distribution of Price Model 3", x = "Price", y = "Frequency") +
  theme_minimal()
```
